{"noir_version":"1.0.0-beta.17+0d6984c7c643b690e6559351f0cb36ce62b44b26","hash":"17202319763947810390","abi":{"parameters":[{"name":"in_owner","type":{"kind":"field"},"visibility":"private"},{"name":"in_value","type":{"kind":"field"},"visibility":"private"},{"name":"in_secret","type":{"kind":"field"},"visibility":"private"},{"name":"in_merkle_path","type":{"kind":"array","length":32,"type":{"kind":"field"}},"visibility":"private"},{"name":"in_path_indices","type":{"kind":"array","length":32,"type":{"kind":"boolean"}},"visibility":"private"},{"name":"out1_owner","type":{"kind":"field"},"visibility":"private"},{"name":"out1_value","type":{"kind":"field"},"visibility":"private"},{"name":"out1_secret","type":{"kind":"field"},"visibility":"private"},{"name":"out2_owner","type":{"kind":"field"},"visibility":"private"},{"name":"out2_value","type":{"kind":"field"},"visibility":"private"},{"name":"out2_secret","type":{"kind":"field"},"visibility":"private"},{"name":"input_nullifier","type":{"kind":"field"},"visibility":"public"},{"name":"output_commitment_1","type":{"kind":"field"},"visibility":"public"},{"name":"output_commitment_2","type":{"kind":"field"},"visibility":"public"},{"name":"merkle_root","type":{"kind":"field"},"visibility":"public"}],"return_type":null,"error_types":{"11508791471511557035":{"error_kind":"string","string":"1001"},"16342668876788388985":{"error_kind":"string","string":"1003"},"17214320417536686225":{"error_kind":"string","string":"1002"}}},"bytecode":"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","debug_symbols":"vZjNbtpAFIXfxWsWc+7891WqKiKJEyEhgghEqqK8e+30HAMLW4ipurqDzf0YxudjsD+75/7x9Pqw2b28vXc/fn52j4fNdrt5fdi+Pa2Pm7fdcPTza9Xp5cPx0PfDoe7i/NC1Xx/63bH7sTttt6vuY709fb/pfb/efdfj+jCcdauu3z0PdQC+bLb9OPpanbvdfCuyC+xGDmECRFwRsECwM8EMZ0K+Itg8wQcQ4Es+98erfr/QH439AWnqT9efH+b7zUolwLyzOUJcWAMkTQEo8Z45ZCTNIXs3R8hLVzL76UrW2W9R5gk1RAJqLHf0w9m0Ci7NrgIW4hgKNIdQ4vlLoN68DNXpYqLa7DIsBdqnLEKAnws0WhOJ9kiiPZNoDyXaU4nWWKI9l9aeS/y/YIYyG8wFQnLaK1Ccm/2tXsjEMAethE8XsRouzc2I7KYf/OzKfYiSpz3D+1lEbnTUSrOjVpsdXZzFbY56NDvqrdHRJcCNjvrQ7OjiSjQ7ag5TKJzPc4b53Pp3qDQm29fmZAfXnOzFWdyW7GDNyQ6+MdlLgBuTHWJzshdX4t8mO6d7dp+aykS4iNXtBMO0loZ4fa/xa3i1ftocru6wOm9jAFed96xhbB1qZE2secz6UMvoz1Dr3xocK1iN1bMG1siaWDMreYG8SF4kL5IXyYvkRfIieZG8SF4kL5GXyEvkJfISeYm8RF4iL5GXyMvkZfIyeZm8TF4mL5OXycvkZfIKeYW8Ql4hr5BXyCvkFfIKeYW8Sl4lr5JXyavkVfIqeZW8Sl4lD85pAA1MA69B0CBqkDTIGhQNRIbIEBkiQ2SIDJEhMkSGyBDZRDaRTWQT2UQ2kU1kE9lENpG9yF5kL7IX2YvsRfYie5GlEeQRJBJkEqQS5BIkE2QTpBPkEyQUZBSkFOQUJBVkFaQV5BUkFmQWpBbkFiQXZBekF+QXJBhkGKQY5BgkGWQZpBnkGSQaZBqkGuQaJBtkG6Qb5BskHGQcpBzkHCQdZB2kHeQdJB5kHqQe5B4kH2QfpB/kHyQgZCBGBcf/9hgdDMMWb6ODoYwD6IjpyECO497/sT5s1o/bns/NXk67p4vHaMffe53Rg7b94e2pfz4d+nFD+D43bBF/AA==","file_map":{"19":{"source":"// Exposed only for usage in `std::meta`\npub(crate) mod poseidon2;\n\nuse crate::default::Default;\nuse crate::embedded_curve_ops::{\n    EmbeddedCurvePoint, EmbeddedCurveScalar, multi_scalar_mul, multi_scalar_mul_array_return,\n};\nuse crate::meta::derive_via;\n\n#[foreign(sha256_compression)]\n// docs:start:sha256_compression\npub fn sha256_compression(input: [u32; 16], state: [u32; 8]) -> [u32; 8] {}\n// docs:end:sha256_compression\n\n#[foreign(keccakf1600)]\n// docs:start:keccakf1600\npub fn keccakf1600(input: [u64; 25]) -> [u64; 25] {}\n// docs:end:keccakf1600\n\npub mod keccak {\n    #[deprecated(\"This function has been moved to std::hash::keccakf1600\")]\n    pub fn keccakf1600(input: [u64; 25]) -> [u64; 25] {\n        super::keccakf1600(input)\n    }\n}\n\n#[foreign(blake2s)]\n// docs:start:blake2s\npub fn blake2s<let N: u32>(input: [u8; N]) -> [u8; 32]\n// docs:end:blake2s\n{}\n\n// docs:start:blake3\npub fn blake3<let N: u32>(input: [u8; N]) -> [u8; 32]\n// docs:end:blake3\n{\n    if crate::runtime::is_unconstrained() {\n        // Temporary measure while Barretenberg is main proving system.\n        // Please open an issue if you're working on another proving system and running into problems due to this.\n        crate::static_assert(\n            N <= 1024,\n            \"Barretenberg cannot prove blake3 hashes with inputs larger than 1024 bytes\",\n        );\n    }\n    __blake3(input)\n}\n\n#[foreign(blake3)]\nfn __blake3<let N: u32>(input: [u8; N]) -> [u8; 32] {}\n\n// docs:start:pedersen_commitment\npub fn pedersen_commitment<let N: u32>(input: [Field; N]) -> EmbeddedCurvePoint {\n    // docs:end:pedersen_commitment\n    pedersen_commitment_with_separator(input, 0)\n}\n\n#[inline_always]\npub fn pedersen_commitment_with_separator<let N: u32>(\n    input: [Field; N],\n    separator: u32,\n) -> EmbeddedCurvePoint {\n    let mut points = [EmbeddedCurveScalar { lo: 0, hi: 0 }; N];\n    for i in 0..N {\n        // we use the unsafe version because the multi_scalar_mul will constrain the scalars.\n        points[i] = from_field_unsafe(input[i]);\n    }\n    let generators = derive_generators(\"DEFAULT_DOMAIN_SEPARATOR\".as_bytes(), separator);\n    multi_scalar_mul(generators, points)\n}\n\n// docs:start:pedersen_hash\npub fn pedersen_hash<let N: u32>(input: [Field; N]) -> Field\n// docs:end:pedersen_hash\n{\n    pedersen_hash_with_separator(input, 0)\n}\n\n#[no_predicates]\npub fn pedersen_hash_with_separator<let N: u32>(input: [Field; N], separator: u32) -> Field {\n    let mut scalars: [EmbeddedCurveScalar; N + 1] = [EmbeddedCurveScalar { lo: 0, hi: 0 }; N + 1];\n    let mut generators: [EmbeddedCurvePoint; N + 1] =\n        [EmbeddedCurvePoint::point_at_infinity(); N + 1];\n    let domain_generators: [EmbeddedCurvePoint; N] =\n        derive_generators(\"DEFAULT_DOMAIN_SEPARATOR\".as_bytes(), separator);\n\n    for i in 0..N {\n        scalars[i] = from_field_unsafe(input[i]);\n        generators[i] = domain_generators[i];\n    }\n    scalars[N] = EmbeddedCurveScalar { lo: N as Field, hi: 0 as Field };\n\n    let length_generator: [EmbeddedCurvePoint; 1] =\n        derive_generators(\"pedersen_hash_length\".as_bytes(), 0);\n    generators[N] = length_generator[0];\n    multi_scalar_mul_array_return(generators, scalars, true)[0].x\n}\n\n#[field(bn254)]\n#[inline_always]\npub fn derive_generators<let N: u32, let M: u32>(\n    domain_separator_bytes: [u8; M],\n    starting_index: u32,\n) -> [EmbeddedCurvePoint; N] {\n    crate::assert_constant(domain_separator_bytes);\n    // TODO(https://github.com/noir-lang/noir/issues/5672): Add back assert_constant on starting_index\n    __derive_generators(domain_separator_bytes, starting_index)\n}\n\n#[builtin(derive_pedersen_generators)]\n#[field(bn254)]\nfn __derive_generators<let N: u32, let M: u32>(\n    domain_separator_bytes: [u8; M],\n    starting_index: u32,\n) -> [EmbeddedCurvePoint; N] {}\n\n#[field(bn254)]\n// Decompose the input 'bn254 scalar' into two 128 bits limbs.\n// It is called 'unsafe' because it does not assert the limbs are 128 bits\n// Assuming the limbs are 128 bits:\n// Assert the decomposition does not overflow the field size.\nfn from_field_unsafe(scalar: Field) -> EmbeddedCurveScalar {\n    // Safety: xlo and xhi decomposition is checked below\n    let (xlo, xhi) = unsafe { crate::field::bn254::decompose_hint(scalar) };\n    // Check that the decomposition is correct\n    assert_eq(scalar, xlo + crate::field::bn254::TWO_POW_128 * xhi);\n    // Check that the decomposition does not overflow the field size\n    let (a, b) = if xhi == crate::field::bn254::PHI {\n        (xlo, crate::field::bn254::PLO)\n    } else {\n        (xhi, crate::field::bn254::PHI)\n    };\n    crate::field::bn254::assert_lt(a, b);\n\n    EmbeddedCurveScalar { lo: xlo, hi: xhi }\n}\n\npub fn poseidon2_permutation<let N: u32>(input: [Field; N], state_len: u32) -> [Field; N] {\n    assert_eq(input.len(), state_len);\n    poseidon2_permutation_internal(input)\n}\n\n#[foreign(poseidon2_permutation)]\nfn poseidon2_permutation_internal<let N: u32>(input: [Field; N]) -> [Field; N] {}\n\n// Generic hashing support.\n// Partially ported and impacted by rust.\n\n// Hash trait shall be implemented per type.\n#[derive_via(derive_hash)]\npub trait Hash {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher;\n}\n\n// docs:start:derive_hash\ncomptime fn derive_hash(s: TypeDefinition) -> Quoted {\n    let name = quote { $crate::hash::Hash };\n    let signature = quote { fn hash<H>(_self: Self, _state: &mut H) where H: $crate::hash::Hasher };\n    let for_each_field = |name| quote { _self.$name.hash(_state); };\n    crate::meta::make_trait_impl(\n        s,\n        name,\n        signature,\n        for_each_field,\n        quote {},\n        |fields| fields,\n    )\n}\n// docs:end:derive_hash\n\n// Hasher trait shall be implemented by algorithms to provide hash-agnostic means.\n// TODO: consider making the types generic here ([u8], [Field], etc.)\npub trait Hasher {\n    fn finish(self) -> Field;\n\n    fn write(&mut self, input: Field);\n}\n\n// BuildHasher is a factory trait, responsible for production of specific Hasher.\npub trait BuildHasher {\n    type H: Hasher;\n\n    fn build_hasher(self) -> H;\n}\n\npub struct BuildHasherDefault<H>;\n\nimpl<H> BuildHasher for BuildHasherDefault<H>\nwhere\n    H: Hasher + Default,\n{\n    type H = H;\n\n    fn build_hasher(_self: Self) -> H {\n        H::default()\n    }\n}\n\nimpl<H> Default for BuildHasherDefault<H>\nwhere\n    H: Hasher + Default,\n{\n    fn default() -> Self {\n        BuildHasherDefault {}\n    }\n}\n\nimpl Hash for Field {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self);\n    }\n}\n\nimpl Hash for u1 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u8 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u16 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u32 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u64 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for u128 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for i8 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as u8 as Field);\n    }\n}\n\nimpl Hash for i16 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as u16 as Field);\n    }\n}\n\nimpl Hash for i32 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as u32 as Field);\n    }\n}\n\nimpl Hash for i64 {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as u64 as Field);\n    }\n}\n\nimpl Hash for bool {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        H::write(state, self as Field);\n    }\n}\n\nimpl Hash for () {\n    fn hash<H>(_self: Self, _state: &mut H)\n    where\n        H: Hasher,\n    {}\n}\n\nimpl<T, let N: u32> Hash for [T; N]\nwhere\n    T: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        for elem in self {\n            elem.hash(state);\n        }\n    }\n}\n\nimpl<T> Hash for [T]\nwhere\n    T: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.len().hash(state);\n        for elem in self {\n            elem.hash(state);\n        }\n    }\n}\n\nimpl<A, B> Hash for (A, B)\nwhere\n    A: Hash,\n    B: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.0.hash(state);\n        self.1.hash(state);\n    }\n}\n\nimpl<A, B, C> Hash for (A, B, C)\nwhere\n    A: Hash,\n    B: Hash,\n    C: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.0.hash(state);\n        self.1.hash(state);\n        self.2.hash(state);\n    }\n}\n\nimpl<A, B, C, D> Hash for (A, B, C, D)\nwhere\n    A: Hash,\n    B: Hash,\n    C: Hash,\n    D: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.0.hash(state);\n        self.1.hash(state);\n        self.2.hash(state);\n        self.3.hash(state);\n    }\n}\n\nimpl<A, B, C, D, E> Hash for (A, B, C, D, E)\nwhere\n    A: Hash,\n    B: Hash,\n    C: Hash,\n    D: Hash,\n    E: Hash,\n{\n    fn hash<H>(self, state: &mut H)\n    where\n        H: Hasher,\n    {\n        self.0.hash(state);\n        self.1.hash(state);\n        self.2.hash(state);\n        self.3.hash(state);\n        self.4.hash(state);\n    }\n}\n\n// Some test vectors for Pedersen hash and Pedersen Commitment.\n// They have been generated using the same functions so the tests are for now useless\n// but they will be useful when we switch to Noir implementation.\n#[test]\nfn assert_pedersen() {\n    assert_eq(\n        pedersen_hash_with_separator([1], 1),\n        0x1b3f4b1a83092a13d8d1a59f7acb62aba15e7002f4440f2275edb99ebbc2305f,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1], 1),\n        EmbeddedCurvePoint {\n            x: 0x054aa86a73cb8a34525e5bbed6e43ba1198e860f5f3950268f71df4591bde402,\n            y: 0x209dcfbf2cfb57f9f6046f44d71ac6faf87254afc7407c04eb621a6287cac126,\n            is_infinite: false,\n        },\n    );\n\n    assert_eq(\n        pedersen_hash_with_separator([1, 2], 2),\n        0x26691c129448e9ace0c66d11f0a16d9014a9e8498ee78f4d69f0083168188255,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2], 2),\n        EmbeddedCurvePoint {\n            x: 0x2e2b3b191e49541fe468ec6877721d445dcaffe41728df0a0eafeb15e87b0753,\n            y: 0x2ff4482400ad3a6228be17a2af33e2bcdf41be04795f9782bd96efe7e24f8778,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3], 3),\n        0x0bc694b7a1f8d10d2d8987d07433f26bd616a2d351bc79a3c540d85b6206dbe4,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3], 3),\n        EmbeddedCurvePoint {\n            x: 0x1fee4e8cf8d2f527caa2684236b07c4b1bad7342c01b0f75e9a877a71827dc85,\n            y: 0x2f9fedb9a090697ab69bf04c8bc15f7385b3e4b68c849c1536e5ae15ff138fd1,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4], 4),\n        0xdae10fb32a8408521803905981a2b300d6a35e40e798743e9322b223a5eddc,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4], 4),\n        EmbeddedCurvePoint {\n            x: 0x07ae3e202811e1fca39c2d81eabe6f79183978e6f12be0d3b8eda095b79bdbc9,\n            y: 0x0afc6f892593db6fbba60f2da558517e279e0ae04f95758587760ba193145014,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5], 5),\n        0xfc375b062c4f4f0150f7100dfb8d9b72a6d28582dd9512390b0497cdad9c22,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5], 5),\n        EmbeddedCurvePoint {\n            x: 0x1754b12bd475a6984a1094b5109eeca9838f4f81ac89c5f0a41dbce53189bb29,\n            y: 0x2da030e3cfcdc7ddad80eaf2599df6692cae0717d4e9f7bfbee8d073d5d278f7,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6], 6),\n        0x1696ed13dc2730062a98ac9d8f9de0661bb98829c7582f699d0273b18c86a572,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6], 6),\n        EmbeddedCurvePoint {\n            x: 0x190f6c0e97ad83e1e28da22a98aae156da083c5a4100e929b77e750d3106a697,\n            y: 0x1f4b60f34ef91221a0b49756fa0705da93311a61af73d37a0c458877706616fb,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7], 7),\n        0x128c0ff144fc66b6cb60eeac8a38e23da52992fc427b92397a7dffd71c45ede3,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7], 7),\n        EmbeddedCurvePoint {\n            x: 0x015441e9d29491b06563fac16fc76abf7a9534c715421d0de85d20dbe2965939,\n            y: 0x1d2575b0276f4e9087e6e07c2cb75aa1baafad127af4be5918ef8a2ef2fea8fc,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7, 8], 8),\n        0x2f960e117482044dfc99d12fece2ef6862fba9242be4846c7c9a3e854325a55c,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7, 8], 8),\n        EmbeddedCurvePoint {\n            x: 0x1657737676968887fceb6dd516382ea13b3a2c557f509811cd86d5d1199bc443,\n            y: 0x1f39f0cb569040105fa1e2f156521e8b8e08261e635a2b210bdc94e8d6d65f77,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9], 9),\n        0x0c96db0790602dcb166cc4699e2d306c479a76926b81c2cb2aaa92d249ec7be7,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9], 9),\n        EmbeddedCurvePoint {\n            x: 0x0a3ceae42d14914a432aa60ec7fded4af7dad7dd4acdbf2908452675ec67e06d,\n            y: 0xfc19761eaaf621ad4aec9a8b2e84a4eceffdba78f60f8b9391b0bd9345a2f2,\n            is_infinite: false,\n        },\n    );\n    assert_eq(\n        pedersen_hash_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 10),\n        0x2cd37505871bc460a62ea1e63c7fe51149df5d0801302cf1cbc48beb8dff7e94,\n    );\n    assert_eq(\n        pedersen_commitment_with_separator([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 10),\n        EmbeddedCurvePoint {\n            x: 0x2fb3f8b3d41ddde007c8c3c62550f9a9380ee546fcc639ffbb3fd30c8d8de30c,\n            y: 0x300783be23c446b11a4c0fabf6c91af148937cea15fcf5fb054abf7f752ee245,\n            is_infinite: false,\n        },\n    );\n}\n","path":"std/hash/mod.nr"},"51":{"source":"use payv_logic::Note;\nuse payv_logic::transfer::main as transfer_main;\nuse payv_logic::transfer::{TxnInputPrivate, TxnInputPublic};\nuse payv_logic::utils::merkle::{MerkleTree, pad_proof_to_depth};\n\n/// Transfer circuit - private transfer between notes (2-in, 2-out)\n///\n/// Public inputs:\n/// - input_nullifiers: Nullifiers for spent notes\n/// - output_commitments: New note commitments\n/// - merkle_root: Current Merkle tree root\n///\n/// Private inputs:\n/// - input notes with their Merkle proofs\n/// - output notes\nfn main(\n    // Input note (private)\n    in_owner: Field,\n    in_value: Field,\n    in_secret: Field,\n    in_merkle_path: [Field; 32],\n    in_path_indices: [bool; 32],\n    // Output note 1 (private)\n    out1_owner: Field,\n    out1_value: Field,\n    out1_secret: Field,\n    // Output note 2 (private)\n    out2_owner: Field,\n    out2_value: Field,\n    out2_secret: Field,\n    // Public inputs\n    input_nullifier: pub Field,\n    output_commitment_1: pub Field,\n    output_commitment_2: pub Field,\n    merkle_root: pub Field,\n) {\n    let input_note = Note::new(in_owner, in_value, in_secret);\n    let output_note_1 = Note::new(out1_owner, out1_value, out1_secret);\n    let output_note_2 = Note::new(out2_owner, out2_value, out2_secret);\n\n    let private_data: TxnInputPrivate<1, 2> = TxnInputPrivate {\n        input_notes: [input_note],\n        output_notes: [output_note_1, output_note_2],\n        merkle_paths: [in_merkle_path],\n        path_indices: [in_path_indices],\n    };\n\n    let public_data: TxnInputPublic<1, 2> = TxnInputPublic {\n        input_nullifiers: [input_nullifier],\n        output_commitments: [output_commitment_1, output_commitment_2],\n        merkle_root,\n    };\n\n    transfer_main(private_data, public_data);\n}\n\n// ------- tests -------\n\n#[test]\npub fn test_transfer_works() {\n    let input_note = Note::new(1, 100, 1234);\n    let output_note_1 = Note::new(1, 60, 1000);\n    let output_note_2 = Note::new(2, 40, 1001);\n\n    // Build a merkle tree with the input note commitment\n    let input_commitment = input_note.commit();\n    let leaves: [Field; 4] = [input_commitment, 0, 0, 0];\n    let tree: MerkleTree<4, 2> = MerkleTree::new(leaves);\n\n    // Generate proof for leaf at index 0 and pad to depth 32\n    let small_proof = tree.generate_proof(0);\n    let (full_root, full_proof) = pad_proof_to_depth::<2, 32>(tree.root, small_proof);\n\n    main(\n        // input\n        1,\n        100,\n        1234,\n        full_proof.path,\n        full_proof.indices,\n        // outputs\n        1,\n        60,\n        1000,\n        2,\n        40,\n        1001,\n        // public\n        input_note.generate_nullifer(),\n        output_note_1.commit(),\n        output_note_2.commit(),\n        full_root,\n    );\n}\n\n#[test(should_fail_with = \"1001\")]\npub fn test_invalid_nullifier_fails() {\n    let input_note = Note::new(1, 100, 1234);\n    let other_note = Note::new(1, 100, 4444);\n\n    let input_commitment = input_note.commit();\n    let leaves: [Field; 4] = [input_commitment, 0, 0, 0];\n    let tree: MerkleTree<4, 2> = MerkleTree::new(leaves);\n    let small_proof = tree.generate_proof(0);\n    let (full_root, full_proof) = pad_proof_to_depth::<2, 32>(tree.root, small_proof);\n\n    let out1 = Note::new(1, 100, 1000);\n    let out2 = Note::new(2, 0, 1001);\n\n    main(\n        1,\n        100,\n        1234,\n        full_proof.path,\n        full_proof.indices,\n        1,\n        100,\n        1000,\n        2,\n        0,\n        1001,\n        other_note.generate_nullifer(), // wrong nullifier\n        out1.commit(),\n        out2.commit(),\n        full_root,\n    );\n}\n\n#[test(should_fail_with = \"1002\")]\npub fn test_value_imbalance_fails() {\n    let input_note = Note::new(1, 100, 1234);\n    let output_note = Note::new(1, 120, 1234);\n    let output_note_2 = Note::new(0, 0, 0);\n\n    let input_commitment = input_note.commit();\n    let leaves: [Field; 4] = [input_commitment, 0, 0, 0];\n    let tree: MerkleTree<4, 2> = MerkleTree::new(leaves);\n    let small_proof = tree.generate_proof(0);\n    let (full_root, full_proof) = pad_proof_to_depth::<2, 32>(tree.root, small_proof);\n\n    main(\n        1,\n        100,\n        1234,\n        full_proof.path,\n        full_proof.indices,\n        1,\n        120,\n        1234,\n        0,\n        0,\n        0,\n        input_note.generate_nullifer(),\n        output_note.commit(),\n        output_note_2.commit(),\n        full_root,\n    );\n}\n","path":"/Users/x/lab/factory/payv/payv-dev/circuit/transfer/src/main.nr"},"55":{"source":"use poseidon::poseidon2;\n\npub struct Note {\n    pub owner: Field,\n    pub value: Field,\n    pub secret: Field,\n}\n\nimpl Note {\n    pub fn new(owner: Field, value: Field, secret: Field) -> Note {\n        Note { owner, value, secret }\n    }\n\n    pub fn commit(self) -> Field {\n        let input = [self.owner, self.value, self.secret];\n        poseidon2::Poseidon2::hash(input, input.len())\n    }\n\n    pub fn generate_nullifer(self) -> Field {\n        let input = [self.commit(), self.secret];\n        poseidon2::Poseidon2::hash(input, input.len())\n    }\n\n    pub fn verify_commitment(self, commitment: Field) -> bool {\n        self.commit() == commitment\n    }\n}\n\n// ------- tests -------\n\n#[test]\npub fn test_note_creation() {\n    let note = Note::new(1, 100, 1234);\n    assert(note.owner == 1);\n    assert(note.value == 100);\n    assert(note.secret == 1234);\n}\n\n#[test]\npub fn test_commitment_deterministic() {\n    let note_1 = Note::new(1, 100, 1234);\n    let note_2 = Note::new(1, 100, 1234);\n    println([note_1.commit(), note_2.commit()]);\n    assert(note_1.commit() == note_2.commit());\n}\n\n#[test]\npub fn test_commitment_uniqueness() {\n    let note_1 = Note::new(1, 100, 1234);\n    let note_2 = Note::new(1, 100, 1233);\n\n    println([note_1.commit(), note_2.commit()]);\n    assert(note_1.commit() != note_2.commit());\n}\n\n#[test]\npub fn test_nullifer_deterministic() {\n    let note_1 = Note::new(1, 100, 1234);\n    let note_2 = Note::new(1, 100, 1234);\n    println([note_1.generate_nullifer(), note_2.generate_nullifer()]);\n    assert(note_1.generate_nullifer() == note_2.generate_nullifer());\n}\n\n#[test]\npub fn test_nullifier_uniqueness() {\n    let note_1 = Note::new(1, 100, 1234);\n    let note_2 = Note::new(1, 100, 1233);\n\n    println([note_1.generate_nullifer(), note_2.generate_nullifer()]);\n    assert(note_1.generate_nullifer() != note_2.generate_nullifer());\n}\n\n#[test]\nfn test_verify_commitment() {\n    let note_1 = Note::new(1, 100, 1234);\n    assert(note_1.verify_commitment(note_1.commit()));\n}\n","path":"/Users/x/lab/factory/payv/payv-dev/circuit/payv_logic/src/models.nr"},"57":{"source":"use super::errors;\nuse super::errors::ERR_MERKLE_INVALID;\nuse super::errors::ERR_VALUE_BALANCES;\nuse super::models::Note;\nuse super::utils::merkle::{MerkleTree, pad_proof_to_depth, verify_merkle};\nuse poseidon::poseidon2;\n\n/// Transfer logic\n/// Uses ...\n/// Todo: decide merkle tree structure\n\npub struct TxnInputPublic<let N: u32, let M: u32> {\n    pub input_nullifiers: [Field; N],\n    pub output_commitments: [Field; M],\n    pub merkle_root: Field,\n}\n\npub struct TxnInputPrivate<let N: u32, let M: u32> {\n    pub input_notes: [Note; N],\n    pub output_notes: [Note; M],\n    pub merkle_paths: [[Field; 32]; N],\n    pub path_indices: [[bool; 32]; N],\n}\n\n// for now default 2,2 until I decide structure of actual data\n/// Support private transfer of notes\n///\n/// Constraints recognized\n/// - ensure nullifiers are correctly computed\n/// - ensure commitments are in merkle tree\n/// - ensure sum(in) = sum(out)\npub fn main<let N: u32, let M: u32>(\n    private_data: TxnInputPrivate<N, M>,\n    public_data: TxnInputPublic<N, M>,\n) {\n    let mut input_amount = 0;\n    let mut output_amount = 0;\n\n    for i in 0..N {\n        let input_note = private_data.input_notes[i];\n        let input_note_commitment = input_note.commit();\n        let input = [input_note_commitment, input_note.secret];\n        // assert nullifiers are correctly passed\n        assert(\n            poseidon2::Poseidon2::hash(input, input.len()) == public_data.input_nullifiers[i],\n            errors::ERR_NULLIFIER_INVALID,\n        );\n        input_amount += input_note.value;\n        // exists in tree\n        assert(\n            verify_merkle(\n                input_note_commitment,\n                public_data.merkle_root,\n                private_data.merkle_paths[i],\n                private_data.path_indices[i],\n            ),\n            ERR_MERKLE_INVALID,\n        );\n    }\n    // verify public commitments\n    for i in 0..M {\n        let output_note = private_data.output_notes[i];\n        output_amount += output_note.value;\n        assert(output_note.commit() == public_data.output_commitments[i]);\n    }\n    // value conservation\n    assert(input_amount == output_amount, ERR_VALUE_BALANCES);\n}\n\n// ------- tests -------\n#[test]\npub fn test_transfer_works() {\n    let input_note = Note::new(1, 100, 1234);\n    let output_note_1 = Note::new(1, 60, 1000);\n    let output_note_2 = Note::new(2, 40, 1001);\n\n    // Build a merkle tree with the input note commitment\n    let input_commitment = input_note.commit();\n    let leaves: [Field; 4] = [input_commitment, 0, 0, 0];\n    let tree: MerkleTree<4, 2> = MerkleTree::new(leaves);\n\n    // Generate proof for leaf at index 0 and pad to depth 32\n    let small_proof = tree.generate_proof(0);\n    let (full_root, full_proof) = pad_proof_to_depth::<2, 32>(tree.root, small_proof);\n\n    let private_data = TxnInputPrivate {\n        input_notes: [input_note],\n        output_notes: [output_note_1, output_note_2],\n        merkle_paths: [full_proof.path],\n        path_indices: [full_proof.indices],\n    };\n    let public_data = TxnInputPublic {\n        input_nullifiers: [input_note.generate_nullifer()],\n        output_commitments: [output_note_1.commit(), output_note_2.commit()],\n        merkle_root: full_root,\n    };\n    main(private_data, public_data);\n}\n\n#[test(should_fail_with = \"1001\")]\npub fn test_invalid_nullifier_fails() {\n    let input_note = Note::new(1, 100, 1234);\n    let other_note = Note::new(1, 100, 4444);\n    let private_data = TxnInputPrivate {\n        input_notes: [input_note],\n        output_notes: [],\n        merkle_paths: [[0; 32]],\n        path_indices: [[false; 32]],\n    };\n    let public_data = TxnInputPublic {\n        // uses other note here\n        input_nullifiers: [other_note.generate_nullifer()],\n        output_commitments: [],\n        merkle_root: 0,\n    };\n    main(private_data, public_data);\n}\n\n#[test(should_fail_with = \"1002\")]\npub fn test_value_imbalance() {\n    let input_note = Note::new(1, 100, 1234);\n    let output_note = Note::new(1, 120, 1234);\n\n    // Build a merkle tree with the input note commitment\n    let input_commitment = input_note.commit();\n    let leaves: [Field; 4] = [input_commitment, 0, 0, 0];\n    let tree: MerkleTree<4, 2> = MerkleTree::new(leaves);\n\n    // Generate proof for leaf at index 0 and pad to depth 32\n    let small_proof = tree.generate_proof(0);\n    let (full_root, full_proof) = pad_proof_to_depth::<2, 32>(tree.root, small_proof);\n\n    let private_data = TxnInputPrivate {\n        input_notes: [input_note],\n        output_notes: [output_note],\n        merkle_paths: [full_proof.path],\n        path_indices: [full_proof.indices],\n    };\n    let public_data = TxnInputPublic {\n        // uses other note here\n        input_nullifiers: [input_note.generate_nullifer()],\n        output_commitments: [output_note.commit()],\n        merkle_root: full_root,\n    };\n    main(private_data, public_data);\n}\n","path":"/Users/x/lab/factory/payv/payv-dev/circuit/payv_logic/src/transfer.nr"},"58":{"source":"use poseidon::poseidon2;\n\n/// Merkle proof containing path and indices for verification\npub struct MerkleProof<let DEPTH: u32> {\n    pub path: [Field; DEPTH],\n    pub indices: [bool; DEPTH],\n}\n\n/// Merkle tree with configurable depth\n/// N = number of leaves (must be power of 2)\n/// DEPTH = tree depth (log2(N))\npub struct MerkleTree<let N: u32, let DEPTH: u32> {\n    pub leaves: [Field; N],\n    pub root: Field,\n    // Store all nodes level by level (excluding leaves and root)\n    // Total intermediate nodes = N - 1 - (root) = N - 2... but we store N-1 to include all levels\n    nodes: [Field; N],\n}\n\nimpl<let N: u32, let DEPTH: u32> MerkleTree<N, DEPTH> {\n    /// Create a new Merkle tree from leaves\n    /// Builds the tree bottom-up using Poseidon2 hashing\n    pub fn new(leaves: [Field; N]) -> Self {\n        let mut nodes: [Field; N] = [0; N];\n        let mut current_level: [Field; N] = leaves;\n        let mut level_size = N;\n        let mut node_offset: u32 = 0;\n\n        // Build tree bottom-up, storing intermediate nodes\n        for _level in 0..DEPTH {\n            let pairs = level_size / 2;\n            for i in 0..N / 2 {\n                if i < pairs {\n                    let left = current_level[2 * i];\n                    let right = current_level[2 * i + 1];\n                    let parent = poseidon2::Poseidon2::hash([left, right], 2);\n                    nodes[node_offset + i] = parent;\n                    current_level[i] = parent;\n                }\n            }\n            node_offset += pairs;\n            level_size = pairs;\n        }\n\n        let root = current_level[0];\n        MerkleTree { leaves, root, nodes }\n    }\n\n    /// Generate a Merkle proof for a leaf at the given index\n    /// Returns the sibling path and position indices\n    pub fn generate_proof(self, leaf_index: u32) -> MerkleProof<DEPTH> {\n        let mut path: [Field; DEPTH] = [0; DEPTH];\n        let mut indices: [bool; DEPTH] = [false; DEPTH];\n        let mut current_index = leaf_index;\n        let mut level_size = N;\n        let mut node_offset: u32 = 0;\n\n        for level in 0..DEPTH {\n            // Determine if we're on the left (even) or right (odd)\n            let is_right = (current_index % 2) == 1;\n            indices[level] = is_right;\n\n            // Get sibling index\n            let sibling_index = if is_right {\n                current_index - 1\n            } else {\n                current_index + 1\n            };\n\n            // Get sibling value from appropriate level\n            if level == 0 {\n                // First level: siblings are in leaves\n                path[level] = self.leaves[sibling_index];\n            } else {\n                // Higher levels: siblings are in nodes\n                // Calculate offset into nodes array for this level\n                let prev_offset = node_offset - (level_size);\n                path[level] = self.nodes[prev_offset + sibling_index];\n            }\n\n            // Move to parent index for next level\n            current_index = current_index / 2;\n            if level > 0 {\n                node_offset += level_size / 2;\n            } else {\n                node_offset = N / 2;\n            }\n            level_size = level_size / 2;\n        }\n\n        MerkleProof { path, indices }\n    }\n\n    /// Get the root of the tree\n    pub fn get_root(self) -> Field {\n        self.root\n    }\n}\n\n/// Verify a Merkle proof\n/// Returns true if the leaf is in the tree with the given root\npub fn verify_merkle<let DEPTH: u32>(\n    leaf: Field,\n    root: Field,\n    path: [Field; DEPTH],\n    indices: [bool; DEPTH],\n) -> bool {\n    let mut hash = leaf;\n    for i in 0..DEPTH {\n        let input = if indices[i] {\n            [path[i], hash]\n        } else {\n            [hash, path[i]]\n        };\n        hash = poseidon2::Poseidon2::hash(input, input.len());\n    }\n    hash == root\n}\n\n/// Verify a Merkle proof using the MerkleProof struct\npub fn verify_proof<let DEPTH: u32>(leaf: Field, root: Field, proof: MerkleProof<DEPTH>) -> bool {\n    verify_merkle(leaf, root, proof.path, proof.indices)\n}\n\n/// Pad a smaller tree's proof to a larger depth\n/// Useful when you have a small tree but need a fixed-depth proof\npub fn pad_proof_to_depth<let SMALL_DEPTH: u32, let FULL_DEPTH: u32>(\n    small_root: Field,\n    small_proof: MerkleProof<SMALL_DEPTH>,\n) -> (Field, MerkleProof<FULL_DEPTH>) {\n    let mut full_path: [Field; FULL_DEPTH] = [0; FULL_DEPTH];\n    let mut full_indices: [bool; FULL_DEPTH] = [false; FULL_DEPTH];\n\n    // Copy small proof\n    for i in 0..SMALL_DEPTH {\n        full_path[i] = small_proof.path[i];\n        full_indices[i] = small_proof.indices[i];\n    }\n\n    // Extend root by hashing with zeros\n    let mut extended_root = small_root;\n    for _i in SMALL_DEPTH..FULL_DEPTH {\n        extended_root = poseidon2::Poseidon2::hash([extended_root, 0], 2);\n    }\n\n    (extended_root, MerkleProof { path: full_path, indices: full_indices })\n}\n\n// ============ Tests ============\n\n#[test]\nfn test_merkle_tree_build() {\n    let leaves: [Field; 4] = [100, 200, 300, 400];\n    let tree: MerkleTree<4, 2> = MerkleTree::new(leaves);\n\n    // Manually compute expected root\n    let node_01 = poseidon2::Poseidon2::hash([100, 200], 2);\n    let node_23 = poseidon2::Poseidon2::hash([300, 400], 2);\n    let expected_root = poseidon2::Poseidon2::hash([node_01, node_23], 2);\n\n    assert(tree.root == expected_root);\n}\n\n#[test]\nfn test_merkle_proof_leaf0() {\n    let leaves: [Field; 4] = [100, 200, 300, 400];\n    let tree: MerkleTree<4, 2> = MerkleTree::new(leaves);\n    let proof = tree.generate_proof(0);\n\n    assert(verify_proof(leaves[0], tree.root, proof));\n}\n\n#[test]\nfn test_merkle_proof_leaf3() {\n    let leaves: [Field; 4] = [100, 200, 300, 400];\n    let tree: MerkleTree<4, 2> = MerkleTree::new(leaves);\n    let proof = tree.generate_proof(3);\n\n    assert(verify_proof(leaves[3], tree.root, proof));\n}\n\n#[test]\nfn test_merkle_proof_all_leaves() {\n    let leaves: [Field; 4] = [100, 200, 300, 400];\n    let tree: MerkleTree<4, 2> = MerkleTree::new(leaves);\n\n    for i in 0..4 {\n        let proof = tree.generate_proof(i);\n        assert(verify_proof(leaves[i], tree.root, proof));\n    }\n}\n\n#[test]\nfn test_invalid_leaf_fails() {\n    let leaves: [Field; 4] = [100, 200, 300, 400];\n    let tree: MerkleTree<4, 2> = MerkleTree::new(leaves);\n    let proof = tree.generate_proof(0);\n\n    // Wrong leaf should fail\n    assert(!verify_proof(999, tree.root, proof));\n}\n\n#[test]\nfn test_pad_proof() {\n    let leaves: [Field; 4] = [100, 200, 300, 400];\n    let tree: MerkleTree<4, 2> = MerkleTree::new(leaves);\n    let small_proof = tree.generate_proof(0);\n\n    // Pad to depth 4\n    let (padded_root, padded_proof): (Field, MerkleProof<4>) =\n        pad_proof_to_depth(tree.root, small_proof);\n\n    // Verify the padded proof works\n    assert(verify_proof(leaves[0], padded_root, padded_proof));\n}\n\n#[test]\nfn test_larger_tree() {\n    let leaves: [Field; 8] = [10, 20, 30, 40, 50, 60, 70, 80];\n    let tree: MerkleTree<8, 3> = MerkleTree::new(leaves);\n\n    // Verify all leaves\n    for i in 0..8 {\n        let proof = tree.generate_proof(i);\n        assert(verify_proof(leaves[i], tree.root, proof));\n    }\n}\n","path":"/Users/x/lab/factory/payv/payv-dev/circuit/payv_logic/src/utils/merkle.nr"},"67":{"source":"use std::default::Default;\nuse std::hash::Hasher;\n\ncomptime global RATE: u32 = 3;\n\npub struct Poseidon2 {\n    cache: [Field; 3],\n    state: [Field; 4],\n    cache_size: u32,\n    squeeze_mode: bool, // 0 => absorb, 1 => squeeze\n}\n\nimpl Poseidon2 {\n    #[no_predicates]\n    pub fn hash<let N: u32>(input: [Field; N], message_size: u32) -> Field {\n        Poseidon2::hash_internal(input, message_size, message_size != N)\n    }\n\n    pub(crate) fn new(iv: Field) -> Poseidon2 {\n        let mut result =\n            Poseidon2 { cache: [0; 3], state: [0; 4], cache_size: 0, squeeze_mode: false };\n        result.state[RATE] = iv;\n        result\n    }\n\n    fn perform_duplex(&mut self) {\n        // add the cache into sponge state\n        for i in 0..RATE {\n            // We effectively zero-pad the cache by only adding to the state\n            // cache that is less than the specified `cache_size`\n            if i < self.cache_size {\n                self.state[i] += self.cache[i];\n            }\n        }\n        self.state = crate::poseidon2_permutation(self.state, 4);\n    }\n\n    fn absorb(&mut self, input: Field) {\n        assert(!self.squeeze_mode);\n        if self.cache_size == RATE {\n            // If we're absorbing, and the cache is full, apply the sponge permutation to compress the cache\n            self.perform_duplex();\n            self.cache[0] = input;\n            self.cache_size = 1;\n        } else {\n            // If we're absorbing, and the cache is not full, add the input into the cache\n            self.cache[self.cache_size] = input;\n            self.cache_size += 1;\n        }\n    }\n\n    fn squeeze(&mut self) -> Field {\n        assert(!self.squeeze_mode);\n        // If we're in absorb mode, apply sponge permutation to compress the cache.\n        self.perform_duplex();\n        self.squeeze_mode = true;\n\n        // Pop one item off the top of the permutation and return it.\n        self.state[0]\n    }\n\n    fn hash_internal<let N: u32>(\n        input: [Field; N],\n        in_len: u32,\n        is_variable_length: bool,\n    ) -> Field {\n        let two_pow_64 = 18446744073709551616;\n        let iv: Field = (in_len as Field) * two_pow_64;\n        let mut sponge = Poseidon2::new(iv);\n        for i in 0..input.len() {\n            if i < in_len {\n                sponge.absorb(input[i]);\n            }\n        }\n\n        // In the case where the hash preimage is variable-length, we append `1` to the end of the input, to distinguish\n        // from fixed-length hashes. (the combination of this additional field element + the hash IV ensures\n        // fixed-length and variable-length hashes do not collide)\n        if is_variable_length {\n            sponge.absorb(1);\n        }\n        sponge.squeeze()\n    }\n}\n\npub struct Poseidon2Hasher {\n    _state: [Field],\n}\n\nimpl Hasher for Poseidon2Hasher {\n    fn finish(self) -> Field {\n        let iv: Field = (self._state.len() as Field) * 18446744073709551616; // iv = (self._state.len() << 64)\n        let mut sponge = Poseidon2::new(iv);\n        for i in 0..self._state.len() {\n            sponge.absorb(self._state[i]);\n        }\n        sponge.squeeze()\n    }\n\n    fn write(&mut self, input: Field) {\n        self._state = self._state.push_back(input);\n    }\n}\n\nimpl Default for Poseidon2Hasher {\n    fn default() -> Self {\n        Poseidon2Hasher { _state: &[] }\n    }\n}\n","path":"/Users/x/nargo/github.com/noir-lang/poseidon/v0.1.1/src/poseidon2.nr"}},"expression_width":{"Bounded":{"width":4}}}